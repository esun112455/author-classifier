{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "327936fa-ad3f-4e53-87be-ff2e319f9529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "import os\n",
    "from os import listdir\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90d087d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = [\"smollett\",\"dickens\",\"austen\",\"dostoyevsky\",\"alcott\",\"melville\"]\n",
    "texts = {}\n",
    "for author in authors:\n",
    "    files = os.listdir(f\"texts/%s\" % author)\n",
    "    if (f\"%s_extracts.pkl\" % author) in files:\n",
    "        files.remove(f\"%s_extracts.pkl\" % author)\n",
    "    texts[author] = files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68272877",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    labels = []\n",
    "    i = 0\n",
    "    for author in texts:\n",
    "        sample_sentences = []\n",
    "        for text in texts[author]:\n",
    "            full_text = open(f\"texts/%s/%s\" % (author, text), \"r\").read()\n",
    "            full_text = full_text.replace(\"\\n\", \" \")\n",
    "            full_text = full_text.replace(\"\\ufeff\", \"\")\n",
    "            sentences = tokenize.sent_tokenize(full_text)\n",
    "            for sentence in sentences:\n",
    "                sample_sentences += sentences\n",
    "        extracts = open(f\"texts/%s/%s_extracts.pkl\" % (author,author), \"wb\")\n",
    "        pickle.dump(sample_sentences,extracts)\n",
    "        extracts.close()\n",
    "        i += 1\n",
    "except:\n",
    "    extracts.close()\n",
    "    print(\"exception occurred\")\n",
    "    for author in authors:\n",
    "        os.remove(f\"texts/%s/%s_extracts.pkl\" % (author, author))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a5f13e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a32ca2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54fd660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dickens_sentences = pickle.load(open(\"texts/dickens/dickens_extracts.pkl\",\"rb\"))\n",
    "melville_sentences = pickle.load(open(\"texts/melville/melville_extracts.pkl\",\"rb\"))\n",
    "austen_sentences = pickle.load(open(\"texts/austen/austen_extracts.pkl\",\"rb\"))\n",
    "alcott_sentences = pickle.load(open(\"texts/alcott/alcott_extracts.pkl\",\"rb\"))\n",
    "smollett_sentences = pickle.load(open(\"texts/smollett/smollett_extracts.pkl\",\"rb\"))\n",
    "dostoyevsky_sentences = pickle.load(open(\"texts/dostoyevsky/dostoyevsky_extracts.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5528f4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_counts = [len(dickens_sentences), len(melville_sentences), len(austen_sentences), len(alcott_sentences), len(smollett_sentences), len(dostoyevsky_sentences)]\n",
    "sentences = dickens_sentences[0:50000] + melville_sentences[0:50000] + austen_sentences[0:50000] + alcott_sentences[0:50000] + smollett_sentences[0:50000] + dostoyevsky_sentences[0:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dba46dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(np.array(sentences[1::5] + sentences[2::5] + sentences[3::5] + sentences[4::5]))\n",
    "X_dev = tokenizer.texts_to_sequences(np.array(sentences[0::10]))\n",
    "X_test = tokenizer.texts_to_sequences(np.array(sentences[5::10]))\n",
    "\n",
    "labels = [0] * 50000 + [1] * 50000 + [2] * 50000 + [3] * 50000 + [4] * 50000 + [5] * 50000 \n",
    "\n",
    "y_train = np.array(labels[1::5] + labels[2::5] + labels[3::5] + labels[4::5])\n",
    "y_dev = np.array(labels[::10])\n",
    "y_test = np.array(labels[5::10])\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=6)\n",
    "y_dev = to_categorical(y_dev, num_classes=6)\n",
    "y_test = to_categorical(y_test, num_classes=6)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ded57169",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 50\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=max_length)\n",
    "X_dev = pad_sequences(X_dev, padding='post', maxlen=max_length)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9877e6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 50, 50)            1421150   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               60400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                1616      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1483540 (5.66 MB)\n",
      "Trainable params: 1483540 (5.66 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emb_dim = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=vocab_size, \n",
    "                           output_dim=emb_dim, \n",
    "                           input_length=max_length))\n",
    "model.add(layers.LSTM(100, dropout=0.1, recurrent_dropout=0.1))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Dense(6, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f330afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15000/15000 [==============================] - ETA: 0s - loss: 0.5512 - accuracy: 0.7844\n",
      "Epoch 1: saving model to cp.ckpt\n",
      "15000/15000 [==============================] - 850s 56ms/step - loss: 0.5512 - accuracy: 0.7844 - val_loss: 0.5044 - val_accuracy: 0.8468\n",
      "Epoch 2/10\n",
      "14999/15000 [============================>.] - ETA: 0s - loss: 0.1371 - accuracy: 0.9553\n",
      "Epoch 2: saving model to cp.ckpt\n",
      "15000/15000 [==============================] - 706s 47ms/step - loss: 0.1371 - accuracy: 0.9553 - val_loss: 0.8514 - val_accuracy: 0.8564\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - ETA: 0s - loss: 0.0799 - accuracy: 0.9724\n",
      "Epoch 3: saving model to cp.ckpt\n",
      "15000/15000 [==============================] - 780s 52ms/step - loss: 0.0799 - accuracy: 0.9724 - val_loss: 1.2126 - val_accuracy: 0.8548\n",
      "Epoch 4/10\n",
      "14999/15000 [============================>.] - ETA: 0s - loss: 0.0567 - accuracy: 0.9798\n",
      "Epoch 4: saving model to cp.ckpt\n",
      "15000/15000 [==============================] - 773s 52ms/step - loss: 0.0567 - accuracy: 0.9798 - val_loss: 1.4613 - val_accuracy: 0.8502\n",
      "Epoch 5/10\n",
      "10168/15000 [===================>..........] - ETA: 4:01 - loss: 0.0438 - accuracy: 0.9841"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10169/15000 [===================>..........] - ETA: 4:01 - loss: 0.0438 - accuracy: 0.9841"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10170/15000 [===================>..........] - ETA: 4:06 - loss: 0.0438 - accuracy: 0.9841"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10171/15000 [===================>..........] - ETA: 4:11 - loss: 0.0438 - accuracy: 0.9841"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10172/15000 [===================>..........] - ETA: 4:15 - loss: 0.0438 - accuracy: 0.9841"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10173/15000 [===================>..........] - ETA: 4:20 - loss: 0.0438 - accuracy: 0.9841"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10174/15000 [===================>..........] - ETA: 4:25 - loss: 0.0438 - accuracy: 0.9841"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\esun1\\.conda\\envs\\py_env\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10175/15000 [===================>..........] - ETA: 4:29 - loss: 0.0438 - accuracy: 0.9841"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"cp.ckpt\"\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=5,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_dev, y_dev),\n",
    "                    callbacks=cp_callback,\n",
    "                    batch_size=16)\n",
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=True)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=True)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "model_file = open(\"model_file.pkl\", \"wb\")\n",
    "pickle.dump(model, model_file)\n",
    "model_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0854af6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_history(\u001b[43mhistory\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a76541a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 - 10s - loss: 1.3313 - accuracy: 0.8546 - 10s/epoch - 11ms/step\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"cp.ckpt\"\n",
    "model.load_weights(checkpoint_path)\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
